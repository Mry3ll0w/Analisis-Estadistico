---
title: "A3"
author: "Antonio Roldán Andrade"
date: "2025-12-15"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(corrplot)
library(car) # Funcion VIF
library(ggplot2)
```

## 1 Regresión Lineal 

### 1.1 Carga y preparación de los datos

```{r, echo=TRUE}

csv_location <- "salarios_INE_2022_sample.csv"
salariosDataSet <- read.csv(csv_location, sep = ",")

head(salariosDataSet,5)
salariosDataSet <- salariosDataSet %>%
 mutate(
  # 1. CONVERSIÓN Y ETIQUETADO DE VARIABLES CATEGÓRICAS SIMPLES
  
  TIPOPAIS = factor(TIPOPAIS,
                             levels = c(1, 2), 
                             labels = c("España", "Otra")),
   
  SEXO = factor(SEXO,
         levels = c(1, 6), # 1=Hombre, 6=Mujer
         labels = c("Hombre", "Mujer")),

  # ESTU (Nivel de Estudios): Sobrescribe la columna 'ESTU'
  ESTU = factor(ESTU,
         levels = c(1, 2, 3, 4, 5, 6),
         labels = c("1. Sin Estudios/Primaria Incompleta",
              "2. Primaria Completa",
              "3. Secundaria 1ª Etapa (E.S.O.)",
              "4. Secundaria 2ª Etapa (Bachillerato)",
              "5. Formación Profesional",
              "6. Estudios Superiores")),

  # ANOS2 (Grupos de Edad): Sobrescribe la columna 'ANOS2'
  ANOS2 = factor(ANOS2,
         levels = c(1, 2, 3, 4, 5, 6),
         labels = c("1. Menos de 19",
               "2. 20 a 29",
               "3. 30 a 39",
               "4. 40 a 49",
               "5. 50 a 59",
               "6. 60 y más"
              )),


  # 2. RECODIFICACIÓN ESPECÍFICA DE CNACE (Actividad Económica)
 
  CNACE = case_when(
  # Extraemos el primer carácter y comparamos
    substr(CNACE, 1, 1) %in% c("B", "C", "D", "E", "F") ~ "1. Industria y Construcción",
    
    # Nivel 2: O, P, Q
    substr(CNACE, 1, 1) %in% c("O", "P", "Q") ~ "2. Servicios Públicos Clave",
    
    # Nivel 3: El resto (como G1, H2, J0, M0, etc.)
    TRUE ~ "3. Otros Servicios y Actividades"
  ),

  # Creamos la nueva variable
  CNACE_grp = factor(CNACE,
         levels = c("1. Industria y Construcción",
               "2. Servicios Públicos Clave",
               "3. Otros Servicios y Actividades")),


  # 3. RECODIFICACIÓN ESPECÍFICA DE CNO1 
 
  CNO1 = case_when(
   # Nivel 1: A0–C0 (Directores y Técnicos/Profesionales)
   substr(CNO1, 1, 1) %in% c("A", "B", "C") ~ "1. Dirección y Alta Cualificación",
   # Nivel 2: D0–J0 (Técnicos de Apoyo, Empleados, Servicios, Agricultores)
   substr(CNO1, 1, 1) %in% c("D", "E", "F", "G", "H", "I", "J") ~ "2. Cualificación Media",
   # Nivel 3: El resto (K0, L0, M0, N0, O0, P0, Q0)
   TRUE ~ "3. Baja Cualificación y Elementales"
  ),

  # Convertir CNO1 a factor y ordenar los niveles
  CNO1_grp = factor(CNO1,
         levels = c("1. Dirección y Alta Cualificación",
              "2. Cualificación Media",
              "3. Baja Cualificación y Elementales"))
 )



``` 



## 1.2 Estudio de correlación lineal

```{r, echo=TRUE}
# Extraemos todas las variables cuantitativas de la tabla
datos_cuantitativos <- salariosDataSet %>%
  select(where(is.numeric))

# Una vez tenemos los datos procedemos a realizar la matriz de correlacion
matriz_correlacion <- cor(datos_cuantitativos, use = "pairwise.complete.obs")
# 3. Visualizar la matriz
corrplot(matriz_correlacion, 
         method = "circle", # Puedes usar "square" o "number"
         type = "upper",    # Muestra solo la mitad superior
         tl.cex = 0.7,      # Tamaño de la fuente de las etiquetas
         tl.col = "black",  # Color de las etiquetas
         tl.srt = 45,       # Rotación de las etiquetas
         addCoef.col = "black", # Añade el número del coeficiente (opcional)
         number.cex = 0.6)      # Tamaño de los números (si los añades)
```
Como podemos apreciar la matriz es enorme, por lo que realizaremos un filtrado por elementos con una correlación alta (>= 0.7), con esto tendremos una mayor facilidad para obtener un resultado estudiable

```{r, echo=TRUE}

correlaciones_df <- as.data.frame(matriz_correlacion) %>%
  tibble::rownames_to_column("Var1") %>%
  # Nos vamos moviendo para tener una fila por cada par de correlación
  tidyr::pivot_longer(cols = -Var1, names_to = "Var2", values_to = "Correlacion") %>%
  
  # Aseguramos que no comparemos Var1 vs Var2 y Var2 vs Var1, y que no sea la diagonal (Var1 == Var2)
  filter(Var1 < Var2) %>%
  
  # Buscar correlaciones fuertes (|r| > 0.7)
  filter(abs(Correlacion) > 0.7) %>%
  
  # Ordenar por el valor absoluto de la correlación (de más fuerte a más débil)
  arrange(desc(abs(Correlacion)))

# Imprimir las correlaciones más fuertes
print("Pares de variables con correlación |r| > 0.7:")
print(correlaciones_df)

```

Podemos apreciar la existencia de múltiples variables con una fuerte correlación pudiendo destacar:  

- BASE <-> COTIZA: Como es lógico existe una fuerte correlación entre las contribuciones a la seguridad social y la base de cotización a la seguridad social, existe una correlación positiva entre ambas casi completa (0.953).

- JAP <-> JSP1: Cuanto mayor es la jornada laboral anual pactada mayor será la jornada semanal en la mayoría de los casos.

- IRPF <-> RETRINOIN: Consecuentemente, cuanto mayor es el salario bruto anual mayor será la cantidad de IRPF que tendrá que pagar el trabajador.


### 1.4. Generación de los conjuntos de entrenamiento y de test


```{r, echo=TRUE}
# Fijar la semilla para reproducibilidad
set.seed(42)

#`1. Crear el vector de índices para la muestra de entrenamiento (80%) ---

tamano_train <- floor(0.80 * nrow(salariosDataSet))

# seleccionamos los índices de las filas que irán a 'train'
indices_train <- sample(seq_len(nrow(salariosDataSet)), size = tamano_train)

# --- 2. Separar los conjuntos de datos ---

train <- salariosDataSet[indices_train, ]

test <- salariosDataSet[-indices_train, ]

print(paste("Tamaño total:", nrow(salariosDataSet)))
print(paste("Tamaño train (80%):", nrow(train)))
print(paste("Tamaño test (20%):", nrow(test)))

```

### 1.5. Estimación de modelos de regresión lineales simples con variable cualitativa

```{r, echo=TRUE}

# M1: RETRINOIN en función de SEXO
# Usamos Lm ya que estamos en un estudio de regresión lineal simple
modelo_sexo <- lm(RETRINOIN ~ SEXO, data = train)

# Mostrar el resumen del modelo 1
summary(modelo_sexo)

```
__Como podemos apreciar en el resultado anterior, tenemos:__  
1) El salario medio estimado del grupo de referencia (hombre, b0) es de $31053.9$  
2) La diferencia salarial media estimada de las mujeres respecto a los hombres es de $-6472.0$  
3) El salario medio del grupo menos favorecido (mujeres) es:  
$$\text{Salario}_{\text{Resto del Mundo}} = \text{Intercepto} + \text{Coeficiente}_{\text{TIPOPAIS2}}$$

__Con respecto a la si estas estadísticas son significativas tenemos:__  

Puesto que el p-valor del coeficiente es <2e-16, esto implica que dado que es un valor extremadamente pequeño y es mucho menor 
que el umbral de significación (alpha = 0.05) por tanto podemos rechazar la hipotesis nula (Ho: coeficiente es 0).

Por tanto podemos decir que la diferencia salarial media estimada de $-6472.0$ es estadísticamente significativa. 

__Si nos centramos en la interpretación de $R^2$ tenemos:__
El valor obtenido R-Squared es del 1.731 %, por lo que podemos decir la variable SEXO influye únicamente en el $1.73%$ de la variabilidad de la varianza pudiendo asumir que aún siendo la diferencia salarial es estadísticamente significativa, el modelo es débil desde el punto de vista predictivo. La mayor parte de la variación salarial ($\approx 98.27\%$) se debe a otros factores no incluidos en este modelo simple.




```{r, echo=TRUE}
modelo_pais <- lm(RETRINOIN ~ TIPOPAIS, data = train)

# Mostrar el resumen del modelo 1
summary(modelo_pais)

```

__Como podemos apreciar en el resultado del segundo caso, tenemos:__  
1) El salario medio estimado del grupo de referencia (TIPOPAIS 1: España) es de $34080$.  
2) La diferencia salarial media estimada de los trabajadores con nacionalidad Resto del Mundo (TIPOPAIS 2) respecto a los de España es de $-5547$.  
3) El salario medio del grupo menos favorecido (Resto del Mundo) es:

$$\text{Salario}_{\text{Resto del Mundo}} = \text{Salario}_{\text{Medio España}} + \text{Coeficiente}_{\text{TPAIS}} = 34080 + (-5547) = 28533$$
__Con respecto a si estas estadísticas son significativas, tenemos:__  

Puesto que el $p$-valor del coeficiente es $2.2\text{e-}07$, esto implica que dado que es un valor extremadamente pequeño y es mucho menor que el umbral de significación ($\alpha = 0.05$), por lo tanto podemos rechazar la hipótesis nula ($H_0$: el coeficiente es 0).  
Por lo tanto, podemos decir que la diferencia salarial media estimada de $-5547$ es estadísticamente significativa.  

__Si nos centramos en la interpretación de $R^2$ tenemos:__  
El valor obtenido $R^2$ Ajustado es del $0.3227\%$ ($0.003227$), por lo que podemos decir la variable $TIPOPAIS$ influye únicamente en el $0.3227\%$ de la variabilidad de la varianza de la retribución, pudiendo asumir que aun siendo la diferencia salarial estadísticamente significativa, el modelo es extremadamente débil desde el punto de vista predictivo.  
La mayor parte de la variación salarial ($\approx 99.68\%$) se debe a otros factores no incluidos en este modelo simple.

### 1.6 Estimación del modelo de regresión lineal múltiple con predictores cuantitativos

Haremos ahora las regresiones lineales para la variables RETROIN, ANOANTI y JAP:

```{r, echo=TRUE}

modelo_antiguedad_jornada <- lm(RETRINOIN ~ ANOANTI + JAP, data = train)

summary(modelo_antiguedad_jornada)

```

Del resultado mostrado en la regresión lineal podemos inferir:  

1) La variable independiente representa la retribución de un trabajador con 0 experiencia y 0 horas de jornada laboral anual, esto nos ayuda para los cálculos posteriores.  

2) La variable ANOANTI nos indica que por cada año que pasa la retribución aumenta $712.9$ euros.  

3) Por cada hora adicional pactada anualmente la retribución aumenta $16,36$ euros.  

__Interpretación de $R^2$ Ajustado__  

1) El $R^2$ Ajustado del $14.9\%$ es sustancialmente mayor que los modelos simples anteriores (M1 con $\approx 1.73\%$ y M2 con $\approx 0.32\%$).  

2) Confirmando que las variables cuantitativas de "cantidad de trabajo y experiencia" son, efectivamente, mejores predictores de la retribución que las variables categóricas de sexo o nacionalidad.  

3) El modelo sigue siendo moderadamente débil, ya que el $85.1\%$ restante de la variabilidad en el salario se explica por otros factores.  


## 1.7 Estimación del modelo de regresión lineal múltiple con predictores cuantitativos y cualitativos

Para dar respuesta a este ejercicio ajustamos el modelo de la siguiente manera:  
$$\text{RETRINOIN} \sim \text{ANOANTI} + \text{JAP} + \text{SEXO} + \text{TIPOPAIS} + \text{ESTU} + \text{ANOS2} + \text{CNO1_grp}$$  



```{r, echo=TRUE}
                                


modelo_completo <- lm(RETRINOIN ~ ANOANTI + JAP + SEXO + TIPOPAIS + ESTU + 
                                  ANOS2 + CNO1_grp, 
                                  data = train)

# Mostrar el resumen del modelo y calcular VIF
print("--- Resumen del Modelo Completo (M4_final) ---")
summary(modelo_completo)

vif(modelo_completo)


```

Basandonos en los datos aportados podemos inferir:  

1. Todas las variables usadas deben ser mantenidas en el modelo puesto que todas tienen un valor que oscila desde  $\approx 1.043$ hasta
 $\approx 1.23$, en consecuencia ya que el VIF se encuentra en un nivel muy bajo ($1 < \text{VIF} < 5$) mantenemos todas las variables.


2. Ateniendonos a $R^2$ extraemos que el su valor es del $35.21\%$ por lo que hemos aumentado significativamente el coeficiente de determinación, mejorando el modelo, siendo el del modelo anterior $14.9\%$. Esto nos aporta otro apoyo en la decisión de mantener los factores cualitativos dentro del modelo.

3. $P-Valor$

- SEXOMujer pasa de ser nada significativa a tener una gran significancia ($< 2e-16$)

- ESTU: Los niveles de estudio solo poseen significancia a partir de aquellos con Formación Profesional, siendo los 3 primeros niveles (ESTU2-4) nada significativos y viendo como pasan a influir a partir del grupo 5 en adelante.

- ANOS2: Podemos apreciar al incluir el resto de variables cualitativas como los años de antiguedad no son significativos en ningúno de los niveles.

- CNO1_grp: Podemos ver como si es altamente significativo poseer un nivel de estudios de cualquier tipo, $< 2e-16$


4. La unica variable candidata a ser eliminada (a pesar de su VIF) es ANOS2, puesto que ninguno de sus niveles aporta significancia al modelo.  

De tal manera el modelo final será:  
$$\text{RETRINOIN} \sim \text{ANOANTI} + \text{JAP} + \text{SEXO} + \text{TIPOPAIS} + \text{ESTU} + \text{CNO1_grp}$$
```{r, echo=TRUE}

modelo_completov2 <- lm(RETRINOIN ~ ANOANTI + JAP + SEXO + TIPOPAIS + ESTU + 
                                   CNO1_grp, 
                                  data = train)

# Mostrar el resumen del modelo 
print("--- Resumen del Modelo Completo (M4_final) ---")
summary(modelo_completov2)

```



Si comparamos el modelo final con el inicial podemos ver como el coeficiente de SexoMujer se ve incrementado de $-6472$ a $-6709.35$.  
Esto sucede al no controlar la variable años de antiguedad entre otras posible causas:  

1. Evidencia de Alta Discriminación Residual: La brecha de $-6709.35$ es la diferencia salarial media entre hombres y mujeres que poseen exactamente el mismo perfil objetivo (misma antigüedad, jornada, nivel de estudios y cualificación ocupacional).

2. Implicación Inusual: El hecho de que la brecha ajustada sea mayor que la bruta sugiere que, en promedio, las mujeres en la muestra podrían tener características (como la antigüedad o un nivel de estudios superior) que, en un modelo sin el factor "Sexo", les darían una prima salarial. Sin embargo, esta ventaja es negada por la penalización del factor "Sexo".  

En cambio si nos centramos en la Brecha salarial por Nacionalidad tenemos que se reduce significativamente dicha brecha,  pasa de ser una penalización significativa de $-5547$ (los extranjeros ganan menos) a una prima positiva de $+1331.59$.  

1. Brecha Explicada por Capital Humano: La gran diferencia negativa en el modelo inicial era una brecha bruta. Esto significa que los trabajadores de nacionalidad "Otra" tenían, en promedio, características que penalizan fuertemente el salario (ej. menor antigüedad reconocida, concentración en ocupaciones de menor remuneración o estudios no convalidados...

2.  Al incluir los factores de control ($\text{ANOANTI}$, $\text{ESTU}$, $\text{CNO1\_grp}$), estas características que penalizaban el salario son absorbidas por el modelo. Una vez que se comparan trabajadores de idéntico perfil objetivo (un español vs. un extranjero con la misma antigüedad y ocupación), la nacionalidad "Otra" está asociada a una prima de $1331.59$ euros.

__NOTA:__ Es importante resaltar que esta prima de $+1331.59$ es solo marginalmente no significativa a $\alpha=0.05$ (ya que $p = 0.0573$). Esto sugiere que, mientras que el factor de nacionalidad ya no es una desventaja salarial ajustada, la ventaja es demasiado débil para afirmarla con alta confianza estadística.  



### 1.8 Diagnosis del modelo 

```{r, echo=TRUE}

# 1. Gráfico de Residuos vs. Valores Ajustados
plot(modelo_completov2, which = 1)
```
  
  
En el primer gráfico (Residual vs Fitted) estudiaremos la homocedasticidad de los datos, pudiendo sacar las siguientes conclusiones:  

1. Se observa un claro patrón de "embudo" o "abanico". Conforme aumentan los valores ajustados (el salario predicho), la dispersión de los residuos se hace mayor, especialmente por la presencia de valores muy altos en la parte superior derecha.

2. Existe heterocedasticidad, debido a que la varianza de los errores no es constante, lo que indica que el modelo es mucho más preciso para predecir salarios bajos y medios que para capturar la variabilidad de los salarios más altos.


```{r, echo=TRUE}

# 2. Gráfico Q-Q de Normalidad
plot(modelo_completov2, which = 2)

```
  
Si nos centramos en los valores del segundo gráfico (Q-Q Residuals) extraemos lo siguiente:  

1. Este compara los cuantiles de los residuos estandarizados con los de una distribución normal teórica.

2. Los puntos se desvían drásticamente de la línea discontinua en el extremo derecho (cuantiles teóricos superiores a 2). Se identifican observaciones de valores atípicos extremos, como las etiquetadas con los números 26350, 22249 y 45370.

3. Los residuos no siguen una distribución normal. Presentan una fuerte asimetría positiva (poseen una cola pesada a la derecha), causada por individuos con salarios excepcionalmente altos que el modelo no logra explicar totalmente con las variables actuales.


### 1.9 Predicción del modelo

Usaremos el modelo final para la realización de este apartado ya que es el más completo.  

```{r,echo=TRUE}
# 1. Realizar predicciones sobre el conjunto test
predicciones <- predict(modelo_completov2, newdata = test)

# Damos X= 0 y pendiente de 1 (Valor predicho será igual al observado)
ggplot(data = test, aes(x = predicciones, y = RETRINOIN)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Valores Predichos vs. Valores Observados (Test Set)",
       x = "Salario Predicho",
       y = "Salario Observado") 
```
  
Con respecto al la representación gráfica podemos destacar lo siguiente:

1. Línea Roja Discontinua: Representa el escenario ideal donde la predicción coincide exactamente con el valor real ($y = x$). A mayor cercanía de los puntos de esta línea, más preciso es el modelo.

2. Distribución de los Puntos: Se observa una mayor densidad de puntos azules concentrados en torno a la línea roja para salarios bajos y medios (entre 10,000 y 40,000 euros aproximadamente). Esto indica que el modelo tiene una capacidad predictiva aceptable para el grueso de la muestra laboral.

3. Desviación en Salarios Altos: A partir de los 40,000 euros predichos, los puntos observados comienzan a dispersarse significativamente hacia arriba de la línea roja.


```{r, echo=TRUE}


# 2. Calcular el error (Observado - Predicho)
errores <- test$RETRINOIN - predicciones

rmse_valor <- sqrt(mean(errores^2, na.rm = TRUE))
print(paste("RMSE del modelo final:", round(rmse_valor, 2)))

```

Como podemos apreciar el RMSE nos da que las predicciones de los valores reales en las mismas unidades que la variable dependiente es de $13205.36$ euros.  

Este se ve fuertemente influenciado por estas grandes desviaciones en los salarios elevados, por tanto podemos concluir que el modelo explica bien las tendencias generales y las brechas de género o nacionalidad, tiene dificultades para predecir con exactitud salarios en los niveles ejecutivos o de alta dirección.



# 2 Regresión Logística

### 2.1 Preparación de los datos (Binarización)

```{r,echo=TRUE}

# 1. Comenzamos con el calculo de la mediana global del salario anual neto
mediana_salario <- median(salariosDataSet$RETRINOIN, na.rm = TRUE)

# 2. Crear la variable binaria 'SalarioAlto'
# 1 si es superior a la mediana, 0 en caso contrario
salariosDataSet$SalarioAlto <- ifelse(salariosDataSet$RETRINOIN > mediana_salario, 1, 0)

# 3. Convertir a factor 

salariosDataSet$SalarioAlto <- factor(salariosDataSet$SalarioAlto, 
                                      levels = c(0, 1), 
                                      labels = c("No Alto", "Alto"))

# 4. Verificamos que tenemos exactamente a 50/50 los datos 
table(salariosDataSet$SalarioAlto)

# 5. Aplicamos ahora la division entre train y test (similar al modelo 1.4)

tamano_train <- floor(0.80 * nrow(salariosDataSet))

# seleccionamos los índices de las filas que irán a 'train'
indices_train <- sample(seq_len(nrow(salariosDataSet)), size = tamano_train)

# --- 2. Separar los conjuntos de datos ---

train <- salariosDataSet[indices_train, ]

test <- salariosDataSet[-indices_train, ]
# Verificamos de nuevo
print(paste("Tamaño total:", nrow(salariosDataSet)))
print(paste("Tamaño train (80%):", nrow(train)))
print(paste("Tamaño test (20%):", nrow(test)))

```

### 2.2 Estimación del modelo de regresión logística

```{r,echo=TRUE}
# Usaremos GLM ya que la variable Salario Alto es categorica.


salariosDataSet$TIPOCON <- factor(salariosDataSet$TIPOCON, 
                                      levels = c(1, 2), 
                                      labels = c("INDEFINIDO", "DETERMINADO"))

modelo_logistico_base <- glm(SalarioAlto ~ SEXO + ANOANTI + JAP + ESTU + 
                             TIPOCON  +CNACE_grp+ CNO1_grp + TIPOPAIS, 
                             data = train, 
                             family = binomial)

# Visualización del resumen estadístico
summary(modelo_logistico_base)


```
Con respecto a los resultados mostrados podemos determinar las siguientes variables a eliminar:

1. TIPOPAIS: El pvalor mostrado en el grafico es de 0.20 siendo 4 veces mayor al tolerable $\alpha=0.05$, por lo que se puede concluir que no tiene significancai en el modelo.

2. CNACE_grp: A pesar de superar el nivel de tolerancia permitida, este se ve superado por un limite casi minimo $0.0529$, y solo ocurre en uno de los niveles de la categoria por lo que decido considero necesario mantenerla en el estudio.



### 2.3 Cálculo de las OR (Odds-Ratio)

```{r,echo=TRUE}

#OR = e^bi
modelo_logistico_v2 <- glm(SalarioAlto ~ SEXO + ANOANTI + JAP + ESTU + 
                             TIPOCON  +CNACE_grp+ CNO1_grp , 
                             data = train, 
                             family = binomial)

# Creo la tabla usando cbind para mostrar ambas columnas a la vez
OR_TABLE <- exp(cbind(OR = coefficients(modelo_logistico_v2), 
                      confint(modelo_logistico_v2)))
colnames(OR_TABLE) <- c("Odds Ratio", "IC 2.5%", "IC 97.5%")
# Para verlo en pantalla redondeado
round(OR_TABLE, 3)

```

Ateniendonos a la tabla de OR mostrada anteriormente concluyo: 

1. __Factores de Riesgo__ (OR < 1): estas variables aumentan nuestras posibilidades de tener un sueldo alto:   
- Estudios superiores: Nos dan un $22.51$ más de posibilidades de exito.
- Estudios superiores: Nos dan un $12.69$ más de posibilidades de exito.

2. __Factores de Protección__ (OR >1): Son variables que disminuyen nuestras posibilidades de tener un sueld alto:


- Sexo Mujer: Ser mujer reduce las probabilidades de tener un salario alto a casi un tercio de las que tiene un hombre.

- CNO1_grp: Los grupos de Baja Cualificación ($0.254$) son un factor de riesgo muy fuerte, ya que reduce las probabilidades en un $75%$ aproximadamente.
































